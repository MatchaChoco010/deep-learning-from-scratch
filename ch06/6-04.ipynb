{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6章"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正則化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 過学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークは汎化性能を獲得したいので過学習を起こさないようにするのが重要。複雑で表現力の高いモデルを作るときほど、過学習を抑制するテクニックが必要になってくる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "過学習の起きる原因は主に次の2つ。\n",
    "\n",
    "- パラメータを大量に持ち、表現力の高いモデルであること\n",
    "- 訓練データが少ないこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "わざと過学習を再現する。MNISTデータセットの訓練データを60000個から300個だけ抜き出して、7層のネットワークを試してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train acc:0.12333333333333334, test acc:0.1118\n",
      "epoch:1, train acc:0.15, test acc:0.1338\n",
      "epoch:2, train acc:0.2, test acc:0.1648\n",
      "epoch:3, train acc:0.25, test acc:0.1979\n",
      "epoch:4, train acc:0.27666666666666667, test acc:0.2168\n",
      "epoch:5, train acc:0.3, test acc:0.235\n",
      "epoch:6, train acc:0.3233333333333333, test acc:0.2557\n",
      "epoch:7, train acc:0.3466666666666667, test acc:0.2788\n",
      "epoch:8, train acc:0.39666666666666667, test acc:0.2956\n",
      "epoch:9, train acc:0.41, test acc:0.3195\n",
      "epoch:10, train acc:0.43, test acc:0.3313\n",
      "epoch:11, train acc:0.44333333333333336, test acc:0.3512\n",
      "epoch:12, train acc:0.4666666666666667, test acc:0.3703\n",
      "epoch:13, train acc:0.48333333333333334, test acc:0.3828\n",
      "epoch:14, train acc:0.49666666666666665, test acc:0.3908\n",
      "epoch:15, train acc:0.48, test acc:0.3948\n",
      "epoch:16, train acc:0.5033333333333333, test acc:0.4048\n",
      "epoch:17, train acc:0.52, test acc:0.4142\n",
      "epoch:18, train acc:0.55, test acc:0.4266\n",
      "epoch:19, train acc:0.5766666666666667, test acc:0.4389\n",
      "epoch:20, train acc:0.6, test acc:0.4575\n",
      "epoch:21, train acc:0.6, test acc:0.464\n",
      "epoch:22, train acc:0.6133333333333333, test acc:0.4758\n",
      "epoch:23, train acc:0.6033333333333334, test acc:0.4589\n",
      "epoch:24, train acc:0.6266666666666667, test acc:0.4831\n",
      "epoch:25, train acc:0.6633333333333333, test acc:0.5135\n",
      "epoch:26, train acc:0.6833333333333333, test acc:0.5206\n",
      "epoch:27, train acc:0.68, test acc:0.5303\n",
      "epoch:28, train acc:0.7, test acc:0.5417\n",
      "epoch:29, train acc:0.72, test acc:0.5453\n",
      "epoch:30, train acc:0.7233333333333334, test acc:0.563\n",
      "epoch:31, train acc:0.7266666666666667, test acc:0.5574\n",
      "epoch:32, train acc:0.7466666666666667, test acc:0.5765\n",
      "epoch:33, train acc:0.7433333333333333, test acc:0.5635\n",
      "epoch:34, train acc:0.77, test acc:0.5875\n",
      "epoch:35, train acc:0.78, test acc:0.5886\n",
      "epoch:36, train acc:0.7733333333333333, test acc:0.588\n",
      "epoch:37, train acc:0.79, test acc:0.6017\n",
      "epoch:38, train acc:0.7833333333333333, test acc:0.5995\n",
      "epoch:39, train acc:0.8, test acc:0.6108\n",
      "epoch:40, train acc:0.8166666666666667, test acc:0.6256\n",
      "epoch:41, train acc:0.81, test acc:0.6314\n",
      "epoch:42, train acc:0.8166666666666667, test acc:0.6259\n",
      "epoch:43, train acc:0.83, test acc:0.6379\n",
      "epoch:44, train acc:0.8266666666666667, test acc:0.6397\n",
      "epoch:45, train acc:0.84, test acc:0.6523\n",
      "epoch:46, train acc:0.8466666666666667, test acc:0.6558\n",
      "epoch:47, train acc:0.8433333333333334, test acc:0.6522\n",
      "epoch:48, train acc:0.8633333333333333, test acc:0.6591\n",
      "epoch:49, train acc:0.8666666666666667, test acc:0.6696\n",
      "epoch:50, train acc:0.8566666666666667, test acc:0.6645\n",
      "epoch:51, train acc:0.8533333333333334, test acc:0.6637\n",
      "epoch:52, train acc:0.86, test acc:0.6638\n",
      "epoch:53, train acc:0.87, test acc:0.6779\n",
      "epoch:54, train acc:0.87, test acc:0.6687\n",
      "epoch:55, train acc:0.8766666666666667, test acc:0.6883\n",
      "epoch:56, train acc:0.8766666666666667, test acc:0.6815\n",
      "epoch:57, train acc:0.8766666666666667, test acc:0.6881\n",
      "epoch:58, train acc:0.8866666666666667, test acc:0.6978\n",
      "epoch:59, train acc:0.88, test acc:0.6999\n",
      "epoch:60, train acc:0.8833333333333333, test acc:0.6904\n",
      "epoch:61, train acc:0.8966666666666666, test acc:0.6978\n",
      "epoch:62, train acc:0.9, test acc:0.6941\n",
      "epoch:63, train acc:0.9166666666666666, test acc:0.7089\n",
      "epoch:64, train acc:0.9166666666666666, test acc:0.7007\n",
      "epoch:65, train acc:0.9133333333333333, test acc:0.7009\n",
      "epoch:66, train acc:0.9233333333333333, test acc:0.7092\n",
      "epoch:67, train acc:0.9233333333333333, test acc:0.7152\n",
      "epoch:68, train acc:0.9166666666666666, test acc:0.7115\n",
      "epoch:69, train acc:0.9266666666666666, test acc:0.7188\n",
      "epoch:70, train acc:0.93, test acc:0.7224\n",
      "epoch:71, train acc:0.9333333333333333, test acc:0.7192\n",
      "epoch:72, train acc:0.9366666666666666, test acc:0.7291\n",
      "epoch:73, train acc:0.9433333333333334, test acc:0.7248\n",
      "epoch:74, train acc:0.9366666666666666, test acc:0.7264\n",
      "epoch:75, train acc:0.94, test acc:0.7249\n",
      "epoch:76, train acc:0.94, test acc:0.7307\n",
      "epoch:77, train acc:0.9366666666666666, test acc:0.7297\n",
      "epoch:78, train acc:0.9466666666666667, test acc:0.7272\n",
      "epoch:79, train acc:0.9466666666666667, test acc:0.7252\n",
      "epoch:80, train acc:0.9533333333333334, test acc:0.7426\n",
      "epoch:81, train acc:0.96, test acc:0.7403\n",
      "epoch:82, train acc:0.96, test acc:0.7414\n",
      "epoch:83, train acc:0.9566666666666667, test acc:0.7324\n",
      "epoch:84, train acc:0.9566666666666667, test acc:0.7417\n",
      "epoch:85, train acc:0.96, test acc:0.7374\n",
      "epoch:86, train acc:0.9666666666666667, test acc:0.7421\n",
      "epoch:87, train acc:0.9633333333333334, test acc:0.741\n",
      "epoch:88, train acc:0.9633333333333334, test acc:0.7459\n",
      "epoch:89, train acc:0.9666666666666667, test acc:0.7441\n",
      "epoch:90, train acc:0.9766666666666667, test acc:0.7452\n",
      "epoch:91, train acc:0.97, test acc:0.7433\n",
      "epoch:92, train acc:0.9733333333333334, test acc:0.7486\n",
      "epoch:93, train acc:0.97, test acc:0.7386\n",
      "epoch:94, train acc:0.97, test acc:0.7429\n",
      "epoch:95, train acc:0.97, test acc:0.7466\n",
      "epoch:96, train acc:0.98, test acc:0.7485\n",
      "epoch:97, train acc:0.9766666666666667, test acc:0.7475\n",
      "epoch:98, train acc:0.9766666666666667, test acc:0.7472\n",
      "epoch:99, train acc:0.9766666666666667, test acc:0.746\n",
      "epoch:100, train acc:0.98, test acc:0.7555\n",
      "epoch:101, train acc:0.98, test acc:0.7561\n",
      "epoch:102, train acc:0.9766666666666667, test acc:0.7546\n",
      "epoch:103, train acc:0.9866666666666667, test acc:0.7583\n",
      "epoch:104, train acc:0.99, test acc:0.7563\n",
      "epoch:105, train acc:0.9866666666666667, test acc:0.754\n",
      "epoch:106, train acc:0.9866666666666667, test acc:0.7556\n",
      "epoch:107, train acc:0.9866666666666667, test acc:0.756\n",
      "epoch:108, train acc:0.9866666666666667, test acc:0.7548\n",
      "epoch:109, train acc:0.9866666666666667, test acc:0.7538\n",
      "epoch:110, train acc:0.9866666666666667, test acc:0.7566\n",
      "epoch:111, train acc:0.99, test acc:0.7593\n",
      "epoch:112, train acc:0.99, test acc:0.759\n",
      "epoch:113, train acc:0.9933333333333333, test acc:0.7594\n",
      "epoch:114, train acc:0.9933333333333333, test acc:0.7605\n",
      "epoch:115, train acc:0.9933333333333333, test acc:0.7572\n",
      "epoch:116, train acc:0.9966666666666667, test acc:0.7603\n",
      "epoch:117, train acc:0.9966666666666667, test acc:0.7614\n",
      "epoch:118, train acc:0.9966666666666667, test acc:0.7636\n",
      "epoch:119, train acc:0.9933333333333333, test acc:0.7607\n",
      "epoch:120, train acc:0.9966666666666667, test acc:0.7659\n",
      "epoch:121, train acc:0.9966666666666667, test acc:0.7648\n",
      "epoch:122, train acc:0.9966666666666667, test acc:0.767\n",
      "epoch:123, train acc:0.9966666666666667, test acc:0.7643\n",
      "epoch:124, train acc:0.9966666666666667, test acc:0.7657\n",
      "epoch:125, train acc:0.9966666666666667, test acc:0.7648\n",
      "epoch:126, train acc:0.9966666666666667, test acc:0.7677\n",
      "epoch:127, train acc:0.9966666666666667, test acc:0.767\n",
      "epoch:128, train acc:0.9966666666666667, test acc:0.7687\n",
      "epoch:129, train acc:0.9966666666666667, test acc:0.7653\n",
      "epoch:130, train acc:0.9966666666666667, test acc:0.7692\n",
      "epoch:131, train acc:0.9966666666666667, test acc:0.7683\n",
      "epoch:132, train acc:0.9966666666666667, test acc:0.7666\n",
      "epoch:133, train acc:0.9966666666666667, test acc:0.7651\n",
      "epoch:134, train acc:0.9966666666666667, test acc:0.7665\n",
      "epoch:135, train acc:1.0, test acc:0.7669\n",
      "epoch:136, train acc:1.0, test acc:0.7667\n",
      "epoch:137, train acc:1.0, test acc:0.7664\n",
      "epoch:138, train acc:1.0, test acc:0.7666\n",
      "epoch:139, train acc:1.0, test acc:0.7667\n",
      "epoch:140, train acc:1.0, test acc:0.768\n",
      "epoch:141, train acc:1.0, test acc:0.7669\n",
      "epoch:142, train acc:1.0, test acc:0.7652\n",
      "epoch:143, train acc:1.0, test acc:0.7711\n",
      "epoch:144, train acc:1.0, test acc:0.7706\n",
      "epoch:145, train acc:1.0, test acc:0.7705\n",
      "epoch:146, train acc:1.0, test acc:0.7696\n",
      "epoch:147, train acc:1.0, test acc:0.7722\n",
      "epoch:148, train acc:1.0, test acc:0.7708\n",
      "epoch:149, train acc:1.0, test acc:0.7686\n",
      "epoch:150, train acc:1.0, test acc:0.7731\n",
      "epoch:151, train acc:1.0, test acc:0.7738\n",
      "epoch:152, train acc:1.0, test acc:0.7751\n",
      "epoch:153, train acc:1.0, test acc:0.7731\n",
      "epoch:154, train acc:1.0, test acc:0.7721\n",
      "epoch:155, train acc:1.0, test acc:0.7747\n",
      "epoch:156, train acc:1.0, test acc:0.7739\n",
      "epoch:157, train acc:1.0, test acc:0.7747\n",
      "epoch:158, train acc:1.0, test acc:0.7756\n",
      "epoch:159, train acc:1.0, test acc:0.7745\n",
      "epoch:160, train acc:1.0, test acc:0.776\n",
      "epoch:161, train acc:1.0, test acc:0.7723\n",
      "epoch:162, train acc:1.0, test acc:0.7744\n",
      "epoch:163, train acc:1.0, test acc:0.7709\n",
      "epoch:164, train acc:1.0, test acc:0.7677\n",
      "epoch:165, train acc:1.0, test acc:0.7731\n",
      "epoch:166, train acc:1.0, test acc:0.7734\n",
      "epoch:167, train acc:1.0, test acc:0.7737\n",
      "epoch:168, train acc:1.0, test acc:0.7749\n",
      "epoch:169, train acc:1.0, test acc:0.7767\n",
      "epoch:170, train acc:1.0, test acc:0.7745\n",
      "epoch:171, train acc:1.0, test acc:0.775\n",
      "epoch:172, train acc:1.0, test acc:0.7738\n",
      "epoch:173, train acc:1.0, test acc:0.7752\n",
      "epoch:174, train acc:1.0, test acc:0.7737\n",
      "epoch:175, train acc:1.0, test acc:0.7751\n",
      "epoch:176, train acc:1.0, test acc:0.7746\n",
      "epoch:177, train acc:1.0, test acc:0.7751\n",
      "epoch:178, train acc:1.0, test acc:0.7752\n",
      "epoch:179, train acc:1.0, test acc:0.775\n",
      "epoch:180, train acc:1.0, test acc:0.7775\n",
      "epoch:181, train acc:1.0, test acc:0.7784\n",
      "epoch:182, train acc:1.0, test acc:0.7765\n",
      "epoch:183, train acc:1.0, test acc:0.7749\n",
      "epoch:184, train acc:1.0, test acc:0.7775\n",
      "epoch:185, train acc:1.0, test acc:0.7751\n",
      "epoch:186, train acc:1.0, test acc:0.7753\n",
      "epoch:187, train acc:1.0, test acc:0.7755\n",
      "epoch:188, train acc:1.0, test acc:0.7761\n",
      "epoch:189, train acc:1.0, test acc:0.7767\n",
      "epoch:190, train acc:1.0, test acc:0.7765\n",
      "epoch:191, train acc:1.0, test acc:0.7764\n",
      "epoch:192, train acc:1.0, test acc:0.7767\n",
      "epoch:193, train acc:1.0, test acc:0.7768\n",
      "epoch:194, train acc:1.0, test acc:0.7773\n",
      "epoch:195, train acc:1.0, test acc:0.7764\n",
      "epoch:196, train acc:1.0, test acc:0.7772\n",
      "epoch:197, train acc:1.0, test acc:0.7766\n",
      "epoch:198, train acc:1.0, test acc:0.7766\n",
      "epoch:199, train acc:1.0, test acc:0.7772\n",
      "epoch:200, train acc:1.0, test acc:0.7762\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.optimizer import SGD\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 過学習を再現するために、学習データを削減\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# weight decay（荷重減衰）の設定 =======================\n",
    "weight_decay_lambda = 0 # weight decayを使用しない場合\n",
    "# weight_decay_lambda = 0.1\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n",
    "                        weight_decay_lambda=weight_decay_lambda)\n",
    "optimizer = SGD(lr=0.01)\n",
    "\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0\n",
    "\n",
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
    "\n",
    "        epoch_cnt += 1\n",
    "        if epoch_cnt >= max_epochs:\n",
    "            break\n",
    "\n",
    "\n",
    "# 3.グラフの描画==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データに対しては100%の正答率を誇るがテストデータに対しては75%程度の正答率しかない。\n",
    "訓練データとテストデータに対する正答率の隔たりは過学習を起こしていることによるもの。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "過学習は重みパラメータが大きな値を取ることによって発生することが多くある。そこで、重みのパラメータを小さくなるように、重みの二乗ノルムを損失関数に加える。損失関数が小さくなるように重みを調整するので重み自体も小さくなる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train acc:0.07333333333333333, test acc:0.0704\n",
      "epoch:1, train acc:0.09333333333333334, test acc:0.0785\n",
      "epoch:2, train acc:0.10666666666666667, test acc:0.0882\n",
      "epoch:3, train acc:0.12333333333333334, test acc:0.1039\n",
      "epoch:4, train acc:0.15333333333333332, test acc:0.1169\n",
      "epoch:5, train acc:0.16666666666666666, test acc:0.1282\n",
      "epoch:6, train acc:0.17666666666666667, test acc:0.1432\n",
      "epoch:7, train acc:0.21, test acc:0.1571\n",
      "epoch:8, train acc:0.24666666666666667, test acc:0.1726\n",
      "epoch:9, train acc:0.29, test acc:0.1872\n",
      "epoch:10, train acc:0.30666666666666664, test acc:0.2011\n",
      "epoch:11, train acc:0.3233333333333333, test acc:0.2181\n",
      "epoch:12, train acc:0.32666666666666666, test acc:0.2311\n",
      "epoch:13, train acc:0.38, test acc:0.2475\n",
      "epoch:14, train acc:0.3933333333333333, test acc:0.2589\n",
      "epoch:15, train acc:0.4066666666666667, test acc:0.2762\n",
      "epoch:16, train acc:0.43, test acc:0.2848\n",
      "epoch:17, train acc:0.4533333333333333, test acc:0.2936\n",
      "epoch:18, train acc:0.4666666666666667, test acc:0.3073\n",
      "epoch:19, train acc:0.4666666666666667, test acc:0.3168\n",
      "epoch:20, train acc:0.48, test acc:0.325\n",
      "epoch:21, train acc:0.4866666666666667, test acc:0.3386\n",
      "epoch:22, train acc:0.49333333333333335, test acc:0.3444\n",
      "epoch:23, train acc:0.51, test acc:0.3497\n",
      "epoch:24, train acc:0.5233333333333333, test acc:0.362\n",
      "epoch:25, train acc:0.54, test acc:0.377\n",
      "epoch:26, train acc:0.5366666666666666, test acc:0.3761\n",
      "epoch:27, train acc:0.54, test acc:0.3843\n",
      "epoch:28, train acc:0.5533333333333333, test acc:0.3942\n",
      "epoch:29, train acc:0.5666666666666667, test acc:0.4047\n",
      "epoch:30, train acc:0.57, test acc:0.4098\n",
      "epoch:31, train acc:0.5733333333333334, test acc:0.4154\n",
      "epoch:32, train acc:0.59, test acc:0.4307\n",
      "epoch:33, train acc:0.5833333333333334, test acc:0.4275\n",
      "epoch:34, train acc:0.5833333333333334, test acc:0.4248\n",
      "epoch:35, train acc:0.5933333333333334, test acc:0.4295\n",
      "epoch:36, train acc:0.58, test acc:0.4313\n",
      "epoch:37, train acc:0.58, test acc:0.4387\n",
      "epoch:38, train acc:0.58, test acc:0.4494\n",
      "epoch:39, train acc:0.59, test acc:0.4522\n",
      "epoch:40, train acc:0.6066666666666667, test acc:0.4659\n",
      "epoch:41, train acc:0.63, test acc:0.4771\n",
      "epoch:42, train acc:0.6466666666666666, test acc:0.4887\n",
      "epoch:43, train acc:0.66, test acc:0.4974\n",
      "epoch:44, train acc:0.6466666666666666, test acc:0.496\n",
      "epoch:45, train acc:0.65, test acc:0.4889\n",
      "epoch:46, train acc:0.6566666666666666, test acc:0.4856\n",
      "epoch:47, train acc:0.65, test acc:0.4871\n",
      "epoch:48, train acc:0.65, test acc:0.4849\n",
      "epoch:49, train acc:0.66, test acc:0.4909\n",
      "epoch:50, train acc:0.68, test acc:0.4959\n",
      "epoch:51, train acc:0.68, test acc:0.5037\n",
      "epoch:52, train acc:0.6933333333333334, test acc:0.5238\n",
      "epoch:53, train acc:0.69, test acc:0.5254\n",
      "epoch:54, train acc:0.6933333333333334, test acc:0.5411\n",
      "epoch:55, train acc:0.7166666666666667, test acc:0.565\n",
      "epoch:56, train acc:0.7133333333333334, test acc:0.5606\n",
      "epoch:57, train acc:0.73, test acc:0.5627\n",
      "epoch:58, train acc:0.7433333333333333, test acc:0.582\n",
      "epoch:59, train acc:0.7533333333333333, test acc:0.581\n",
      "epoch:60, train acc:0.7366666666666667, test acc:0.5696\n",
      "epoch:61, train acc:0.7566666666666667, test acc:0.5826\n",
      "epoch:62, train acc:0.7066666666666667, test acc:0.554\n",
      "epoch:63, train acc:0.73, test acc:0.5567\n",
      "epoch:64, train acc:0.7266666666666667, test acc:0.5529\n",
      "epoch:65, train acc:0.74, test acc:0.5624\n",
      "epoch:66, train acc:0.7366666666666667, test acc:0.5715\n",
      "epoch:67, train acc:0.7466666666666667, test acc:0.5646\n",
      "epoch:68, train acc:0.7433333333333333, test acc:0.5557\n",
      "epoch:69, train acc:0.75, test acc:0.5613\n",
      "epoch:70, train acc:0.7566666666666667, test acc:0.5713\n",
      "epoch:71, train acc:0.77, test acc:0.5675\n",
      "epoch:72, train acc:0.75, test acc:0.5691\n",
      "epoch:73, train acc:0.77, test acc:0.5851\n",
      "epoch:74, train acc:0.76, test acc:0.5864\n",
      "epoch:75, train acc:0.7566666666666667, test acc:0.5784\n",
      "epoch:76, train acc:0.7633333333333333, test acc:0.5844\n",
      "epoch:77, train acc:0.7433333333333333, test acc:0.5815\n",
      "epoch:78, train acc:0.7733333333333333, test acc:0.5868\n",
      "epoch:79, train acc:0.79, test acc:0.5947\n",
      "epoch:80, train acc:0.7833333333333333, test acc:0.5978\n",
      "epoch:81, train acc:0.7733333333333333, test acc:0.5894\n",
      "epoch:82, train acc:0.7766666666666666, test acc:0.5999\n",
      "epoch:83, train acc:0.7933333333333333, test acc:0.6039\n",
      "epoch:84, train acc:0.7833333333333333, test acc:0.6048\n",
      "epoch:85, train acc:0.7966666666666666, test acc:0.6011\n",
      "epoch:86, train acc:0.79, test acc:0.6004\n",
      "epoch:87, train acc:0.8033333333333333, test acc:0.6172\n",
      "epoch:88, train acc:0.82, test acc:0.6265\n",
      "epoch:89, train acc:0.8166666666666667, test acc:0.6319\n",
      "epoch:90, train acc:0.8166666666666667, test acc:0.624\n",
      "epoch:91, train acc:0.8233333333333334, test acc:0.6182\n",
      "epoch:92, train acc:0.8133333333333334, test acc:0.634\n",
      "epoch:93, train acc:0.83, test acc:0.6361\n",
      "epoch:94, train acc:0.8066666666666666, test acc:0.6301\n",
      "epoch:95, train acc:0.8366666666666667, test acc:0.6294\n",
      "epoch:96, train acc:0.83, test acc:0.6365\n",
      "epoch:97, train acc:0.8166666666666667, test acc:0.6392\n",
      "epoch:98, train acc:0.83, test acc:0.6349\n",
      "epoch:99, train acc:0.8166666666666667, test acc:0.6244\n",
      "epoch:100, train acc:0.8166666666666667, test acc:0.6298\n",
      "epoch:101, train acc:0.81, test acc:0.6299\n",
      "epoch:102, train acc:0.8233333333333334, test acc:0.6345\n",
      "epoch:103, train acc:0.8233333333333334, test acc:0.6309\n",
      "epoch:104, train acc:0.81, test acc:0.6247\n",
      "epoch:105, train acc:0.8066666666666666, test acc:0.6359\n",
      "epoch:106, train acc:0.8066666666666666, test acc:0.6227\n",
      "epoch:107, train acc:0.7933333333333333, test acc:0.6173\n",
      "epoch:108, train acc:0.82, test acc:0.6363\n",
      "epoch:109, train acc:0.8366666666666667, test acc:0.6363\n",
      "epoch:110, train acc:0.83, test acc:0.6333\n",
      "epoch:111, train acc:0.8333333333333334, test acc:0.6461\n",
      "epoch:112, train acc:0.8166666666666667, test acc:0.6305\n",
      "epoch:113, train acc:0.8, test acc:0.6265\n",
      "epoch:114, train acc:0.8266666666666667, test acc:0.6371\n",
      "epoch:115, train acc:0.8333333333333334, test acc:0.6469\n",
      "epoch:116, train acc:0.8466666666666667, test acc:0.648\n",
      "epoch:117, train acc:0.8366666666666667, test acc:0.653\n",
      "epoch:118, train acc:0.8333333333333334, test acc:0.6419\n",
      "epoch:119, train acc:0.8266666666666667, test acc:0.6441\n",
      "epoch:120, train acc:0.85, test acc:0.6542\n",
      "epoch:121, train acc:0.83, test acc:0.6518\n",
      "epoch:122, train acc:0.8466666666666667, test acc:0.6468\n",
      "epoch:123, train acc:0.8333333333333334, test acc:0.6469\n",
      "epoch:124, train acc:0.8333333333333334, test acc:0.6467\n",
      "epoch:125, train acc:0.86, test acc:0.6522\n",
      "epoch:126, train acc:0.84, test acc:0.6507\n",
      "epoch:127, train acc:0.8333333333333334, test acc:0.6364\n",
      "epoch:128, train acc:0.8366666666666667, test acc:0.6473\n",
      "epoch:129, train acc:0.8366666666666667, test acc:0.638\n",
      "epoch:130, train acc:0.8366666666666667, test acc:0.6449\n",
      "epoch:131, train acc:0.8433333333333334, test acc:0.6566\n",
      "epoch:132, train acc:0.8633333333333333, test acc:0.6475\n",
      "epoch:133, train acc:0.8566666666666667, test acc:0.6557\n",
      "epoch:134, train acc:0.8466666666666667, test acc:0.6523\n",
      "epoch:135, train acc:0.8333333333333334, test acc:0.6378\n",
      "epoch:136, train acc:0.8433333333333334, test acc:0.6427\n",
      "epoch:137, train acc:0.8333333333333334, test acc:0.6432\n",
      "epoch:138, train acc:0.8266666666666667, test acc:0.6402\n",
      "epoch:139, train acc:0.8333333333333334, test acc:0.6394\n",
      "epoch:140, train acc:0.8466666666666667, test acc:0.6563\n",
      "epoch:141, train acc:0.8633333333333333, test acc:0.6483\n",
      "epoch:142, train acc:0.8533333333333334, test acc:0.6552\n",
      "epoch:143, train acc:0.85, test acc:0.659\n",
      "epoch:144, train acc:0.8533333333333334, test acc:0.6628\n",
      "epoch:145, train acc:0.85, test acc:0.6571\n",
      "epoch:146, train acc:0.86, test acc:0.6682\n",
      "epoch:147, train acc:0.8633333333333333, test acc:0.6601\n",
      "epoch:148, train acc:0.8466666666666667, test acc:0.6537\n",
      "epoch:149, train acc:0.8366666666666667, test acc:0.6446\n",
      "epoch:150, train acc:0.8433333333333334, test acc:0.6435\n",
      "epoch:151, train acc:0.8533333333333334, test acc:0.66\n",
      "epoch:152, train acc:0.8433333333333334, test acc:0.6577\n",
      "epoch:153, train acc:0.8366666666666667, test acc:0.6524\n",
      "epoch:154, train acc:0.8266666666666667, test acc:0.6388\n",
      "epoch:155, train acc:0.8633333333333333, test acc:0.6668\n",
      "epoch:156, train acc:0.8566666666666667, test acc:0.662\n",
      "epoch:157, train acc:0.8666666666666667, test acc:0.6674\n",
      "epoch:158, train acc:0.86, test acc:0.6612\n",
      "epoch:159, train acc:0.8566666666666667, test acc:0.6634\n",
      "epoch:160, train acc:0.8566666666666667, test acc:0.6604\n",
      "epoch:161, train acc:0.8533333333333334, test acc:0.6623\n",
      "epoch:162, train acc:0.8533333333333334, test acc:0.6668\n",
      "epoch:163, train acc:0.86, test acc:0.6622\n",
      "epoch:164, train acc:0.87, test acc:0.6689\n",
      "epoch:165, train acc:0.8633333333333333, test acc:0.6697\n",
      "epoch:166, train acc:0.8533333333333334, test acc:0.6564\n",
      "epoch:167, train acc:0.86, test acc:0.6763\n",
      "epoch:168, train acc:0.86, test acc:0.6633\n",
      "epoch:169, train acc:0.87, test acc:0.6667\n",
      "epoch:170, train acc:0.86, test acc:0.6666\n",
      "epoch:171, train acc:0.8666666666666667, test acc:0.6708\n",
      "epoch:172, train acc:0.86, test acc:0.663\n",
      "epoch:173, train acc:0.85, test acc:0.6646\n",
      "epoch:174, train acc:0.86, test acc:0.6664\n",
      "epoch:175, train acc:0.84, test acc:0.65\n",
      "epoch:176, train acc:0.86, test acc:0.67\n",
      "epoch:177, train acc:0.86, test acc:0.6788\n",
      "epoch:178, train acc:0.87, test acc:0.6785\n",
      "epoch:179, train acc:0.8733333333333333, test acc:0.6794\n",
      "epoch:180, train acc:0.87, test acc:0.6792\n",
      "epoch:181, train acc:0.8533333333333334, test acc:0.6733\n",
      "epoch:182, train acc:0.8666666666666667, test acc:0.6689\n",
      "epoch:183, train acc:0.8733333333333333, test acc:0.6687\n",
      "epoch:184, train acc:0.8733333333333333, test acc:0.6731\n",
      "epoch:185, train acc:0.8733333333333333, test acc:0.6764\n",
      "epoch:186, train acc:0.8633333333333333, test acc:0.6737\n",
      "epoch:187, train acc:0.8666666666666667, test acc:0.6738\n",
      "epoch:188, train acc:0.8633333333333333, test acc:0.6726\n",
      "epoch:189, train acc:0.8566666666666667, test acc:0.6577\n",
      "epoch:190, train acc:0.8566666666666667, test acc:0.6673\n",
      "epoch:191, train acc:0.8633333333333333, test acc:0.6662\n",
      "epoch:192, train acc:0.8633333333333333, test acc:0.6693\n",
      "epoch:193, train acc:0.8633333333333333, test acc:0.6739\n",
      "epoch:194, train acc:0.8633333333333333, test acc:0.6653\n",
      "epoch:195, train acc:0.8566666666666667, test acc:0.6712\n",
      "epoch:196, train acc:0.8666666666666667, test acc:0.6783\n",
      "epoch:197, train acc:0.86, test acc:0.6703\n",
      "epoch:198, train acc:0.8766666666666667, test acc:0.6768\n",
      "epoch:199, train acc:0.8666666666666667, test acc:0.6802\n",
      "epoch:200, train acc:0.87, test acc:0.6786\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.optimizer import SGD\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 過学習を再現するために、学習データを削減\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# weight decay（荷重減衰）の設定 =======================\n",
    "#weight_decay_lambda = 0 # weight decayを使用しない場合\n",
    "weight_decay_lambda = 0.1\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n",
    "                        weight_decay_lambda=weight_decay_lambda)\n",
    "optimizer = SGD(lr=0.01)\n",
    "\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0\n",
    "\n",
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
    "\n",
    "        epoch_cnt += 1\n",
    "        if epoch_cnt >= max_epochs:\n",
    "            break\n",
    "\n",
    "\n",
    "# 3.グラフの描画==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隔たりが若干マシになった。訓練データに100%になっていないけどテストデータの正答率もびみょい。やはり訓練データが少ないのは機械学習にとってよろしくない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "過学習を抑制するもう一つの手法としてDropoutというものを試す。\n",
    "\n",
    "訓練時にデータを流すたびにランダムなニューロンを消去する。\n",
    "テスト時にはすべてのニューロンを使って消去した割合をかける。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.311959541886251\n",
      "=== epoch:1, train acc:0.08333333333333333, test acc:0.102 ===\n",
      "train loss:2.299712574084516\n",
      "train loss:2.308541860978123\n",
      "train loss:2.325000853528262\n",
      "=== epoch:2, train acc:0.1, test acc:0.1018 ===\n",
      "train loss:2.2941956310965184\n",
      "train loss:2.3044589395408788\n",
      "train loss:2.3124009632831637\n",
      "=== epoch:3, train acc:0.1, test acc:0.1024 ===\n",
      "train loss:2.306426950432053\n",
      "train loss:2.315692099708714\n",
      "train loss:2.329366679026084\n",
      "=== epoch:4, train acc:0.1, test acc:0.1024 ===\n",
      "train loss:2.3142476121492264\n",
      "train loss:2.3042038814194905\n",
      "train loss:2.3077563568739965\n",
      "=== epoch:5, train acc:0.10666666666666667, test acc:0.1029 ===\n",
      "train loss:2.3003561799229995\n",
      "train loss:2.311593615688454\n",
      "train loss:2.2965386959503804\n",
      "=== epoch:6, train acc:0.10666666666666667, test acc:0.1047 ===\n",
      "train loss:2.308512291896197\n",
      "train loss:2.2908659655690045\n",
      "train loss:2.312924134115078\n",
      "=== epoch:7, train acc:0.10666666666666667, test acc:0.105 ===\n",
      "train loss:2.2985649101172636\n",
      "train loss:2.3176743947186544\n",
      "train loss:2.3109679697849983\n",
      "=== epoch:8, train acc:0.11333333333333333, test acc:0.1054 ===\n",
      "train loss:2.3143001639584493\n",
      "train loss:2.2960703645703604\n",
      "train loss:2.3132638921993545\n",
      "=== epoch:9, train acc:0.11666666666666667, test acc:0.1068 ===\n",
      "train loss:2.3002080762111796\n",
      "train loss:2.30170235925329\n",
      "train loss:2.2995729096887008\n",
      "=== epoch:10, train acc:0.11666666666666667, test acc:0.1089 ===\n",
      "train loss:2.309357308612609\n",
      "train loss:2.287959443119556\n",
      "train loss:2.3029107215532116\n",
      "=== epoch:11, train acc:0.11333333333333333, test acc:0.1085 ===\n",
      "train loss:2.3080523578317407\n",
      "train loss:2.2924709096201807\n",
      "train loss:2.308972621126529\n",
      "=== epoch:12, train acc:0.10666666666666667, test acc:0.1082 ===\n",
      "train loss:2.314436077140907\n",
      "train loss:2.3021927473595363\n",
      "train loss:2.302318201000471\n",
      "=== epoch:13, train acc:0.11, test acc:0.1099 ===\n",
      "train loss:2.300062146214579\n",
      "train loss:2.290738429812838\n",
      "train loss:2.3077908322352703\n",
      "=== epoch:14, train acc:0.11666666666666667, test acc:0.1097 ===\n",
      "train loss:2.301946896668012\n",
      "train loss:2.299697868045331\n",
      "train loss:2.3075768945187844\n",
      "=== epoch:15, train acc:0.12, test acc:0.1095 ===\n",
      "train loss:2.295705888215953\n",
      "train loss:2.2946141557560193\n",
      "train loss:2.291107617237543\n",
      "=== epoch:16, train acc:0.12, test acc:0.1108 ===\n",
      "train loss:2.299846877590954\n",
      "train loss:2.2910714833792234\n",
      "train loss:2.2994230897857686\n",
      "=== epoch:17, train acc:0.11666666666666667, test acc:0.1112 ===\n",
      "train loss:2.2909618427503573\n",
      "train loss:2.2936552703561772\n",
      "train loss:2.2964101587504446\n",
      "=== epoch:18, train acc:0.11666666666666667, test acc:0.1128 ===\n",
      "train loss:2.2965978423517472\n",
      "train loss:2.2887252488049996\n",
      "train loss:2.299445245796252\n",
      "=== epoch:19, train acc:0.11666666666666667, test acc:0.113 ===\n",
      "train loss:2.2917319961485463\n",
      "train loss:2.30628714778347\n",
      "train loss:2.2944267880218443\n",
      "=== epoch:20, train acc:0.11333333333333333, test acc:0.1153 ===\n",
      "train loss:2.293231119090594\n",
      "train loss:2.2990298998038963\n",
      "train loss:2.298130375489544\n",
      "=== epoch:21, train acc:0.12666666666666668, test acc:0.1162 ===\n",
      "train loss:2.2843650164651255\n",
      "train loss:2.2962747167181012\n",
      "train loss:2.2924149875013677\n",
      "=== epoch:22, train acc:0.12666666666666668, test acc:0.1176 ===\n",
      "train loss:2.2919454424466976\n",
      "train loss:2.2864637783869246\n",
      "train loss:2.3130253564378145\n",
      "=== epoch:23, train acc:0.12, test acc:0.117 ===\n",
      "train loss:2.288433528280138\n",
      "train loss:2.279976265209468\n",
      "train loss:2.2938449513478036\n",
      "=== epoch:24, train acc:0.12333333333333334, test acc:0.1191 ===\n",
      "train loss:2.302583123049504\n",
      "train loss:2.289378039081068\n",
      "train loss:2.2979806260803173\n",
      "=== epoch:25, train acc:0.12666666666666668, test acc:0.1179 ===\n",
      "train loss:2.2948578837890654\n",
      "train loss:2.2869139158107386\n",
      "train loss:2.2914780711646925\n",
      "=== epoch:26, train acc:0.13666666666666666, test acc:0.1204 ===\n",
      "train loss:2.289586432240015\n",
      "train loss:2.2874554826879914\n",
      "train loss:2.294828125088633\n",
      "=== epoch:27, train acc:0.13, test acc:0.12 ===\n",
      "train loss:2.286003842510456\n",
      "train loss:2.2887050714844346\n",
      "train loss:2.28422598530825\n",
      "=== epoch:28, train acc:0.13, test acc:0.1182 ===\n",
      "train loss:2.289392598250998\n",
      "train loss:2.2997164055429327\n",
      "train loss:2.2838179394847624\n",
      "=== epoch:29, train acc:0.13, test acc:0.1185 ===\n",
      "train loss:2.2830409611310585\n",
      "train loss:2.2850524062173236\n",
      "train loss:2.289226025662328\n",
      "=== epoch:30, train acc:0.13666666666666666, test acc:0.1217 ===\n",
      "train loss:2.29504904429134\n",
      "train loss:2.28369351880242\n",
      "train loss:2.290063896994947\n",
      "=== epoch:31, train acc:0.13666666666666666, test acc:0.122 ===\n",
      "train loss:2.2863852366809843\n",
      "train loss:2.2801248066826294\n",
      "train loss:2.2827385037372765\n",
      "=== epoch:32, train acc:0.13333333333333333, test acc:0.1225 ===\n",
      "train loss:2.2843748111003945\n",
      "train loss:2.289837923672136\n",
      "train loss:2.29871111028881\n",
      "=== epoch:33, train acc:0.13666666666666666, test acc:0.1228 ===\n",
      "train loss:2.283958761563565\n",
      "train loss:2.2848438088457654\n",
      "train loss:2.283304555360948\n",
      "=== epoch:34, train acc:0.13, test acc:0.1213 ===\n",
      "train loss:2.27983846720619\n",
      "train loss:2.2805953857405257\n",
      "train loss:2.293219495973823\n",
      "=== epoch:35, train acc:0.13, test acc:0.1209 ===\n",
      "train loss:2.28373899866536\n",
      "train loss:2.280086542217374\n",
      "train loss:2.287090898533113\n",
      "=== epoch:36, train acc:0.13333333333333333, test acc:0.1204 ===\n",
      "train loss:2.293406474164144\n",
      "train loss:2.271255249716641\n",
      "train loss:2.2799533058023376\n",
      "=== epoch:37, train acc:0.13, test acc:0.1232 ===\n",
      "train loss:2.2883039483756082\n",
      "train loss:2.287279686830811\n",
      "train loss:2.278697530904998\n",
      "=== epoch:38, train acc:0.13, test acc:0.1225 ===\n",
      "train loss:2.274132142490744\n",
      "train loss:2.277664377098516\n",
      "train loss:2.279572268491138\n",
      "=== epoch:39, train acc:0.13333333333333333, test acc:0.1225 ===\n",
      "train loss:2.2896612972727324\n",
      "train loss:2.2805734191474003\n",
      "train loss:2.2870858951866153\n",
      "=== epoch:40, train acc:0.13, test acc:0.1235 ===\n",
      "train loss:2.284667958544603\n",
      "train loss:2.276187602493186\n",
      "train loss:2.2754837868131013\n",
      "=== epoch:41, train acc:0.13333333333333333, test acc:0.1232 ===\n",
      "train loss:2.279662356718834\n",
      "train loss:2.278425158443232\n",
      "train loss:2.2787285307665717\n",
      "=== epoch:42, train acc:0.13333333333333333, test acc:0.1267 ===\n",
      "train loss:2.2835531222804653\n",
      "train loss:2.27950232293733\n",
      "train loss:2.2845709333730477\n",
      "=== epoch:43, train acc:0.13333333333333333, test acc:0.1257 ===\n",
      "train loss:2.269510071503685\n",
      "train loss:2.287240326763418\n",
      "train loss:2.2753003887872367\n",
      "=== epoch:44, train acc:0.13666666666666666, test acc:0.1287 ===\n",
      "train loss:2.2900156864960923\n",
      "train loss:2.288412037319031\n",
      "train loss:2.275746430981977\n",
      "=== epoch:45, train acc:0.14333333333333334, test acc:0.1289 ===\n",
      "train loss:2.2826307891766895\n",
      "train loss:2.280950469931822\n",
      "train loss:2.2850283815804535\n",
      "=== epoch:46, train acc:0.14, test acc:0.1319 ===\n",
      "train loss:2.2850545049952093\n",
      "train loss:2.278101211842912\n",
      "train loss:2.272832618828581\n",
      "=== epoch:47, train acc:0.15, test acc:0.1332 ===\n",
      "train loss:2.2805994051105882\n",
      "train loss:2.2755601944518076\n",
      "train loss:2.2756850761604936\n",
      "=== epoch:48, train acc:0.14, test acc:0.1338 ===\n",
      "train loss:2.280190799677248\n",
      "train loss:2.2785660571254334\n",
      "train loss:2.2776310720815753\n",
      "=== epoch:49, train acc:0.14, test acc:0.137 ===\n",
      "train loss:2.278531192269071\n",
      "train loss:2.2770670993115396\n",
      "train loss:2.272291569416136\n",
      "=== epoch:50, train acc:0.14, test acc:0.1358 ===\n",
      "train loss:2.2775557314823973\n",
      "train loss:2.272889010939856\n",
      "train loss:2.275804499919044\n",
      "=== epoch:51, train acc:0.14666666666666667, test acc:0.1355 ===\n",
      "train loss:2.283103392980628\n",
      "train loss:2.2798413247466485\n",
      "train loss:2.2853957081479463\n",
      "=== epoch:52, train acc:0.15333333333333332, test acc:0.1362 ===\n",
      "train loss:2.267313145662258\n",
      "train loss:2.2825750013542905\n",
      "train loss:2.2754662868671187\n",
      "=== epoch:53, train acc:0.15666666666666668, test acc:0.1387 ===\n",
      "train loss:2.2681373405835163\n",
      "train loss:2.2580933525648827\n",
      "train loss:2.2619700508651333\n",
      "=== epoch:54, train acc:0.16, test acc:0.1399 ===\n",
      "train loss:2.270649499703937\n",
      "train loss:2.25807181333139\n",
      "train loss:2.266316433595688\n",
      "=== epoch:55, train acc:0.16666666666666666, test acc:0.1429 ===\n",
      "train loss:2.2756755412064105\n",
      "train loss:2.2658723176627107\n",
      "train loss:2.276547272408867\n",
      "=== epoch:56, train acc:0.16666666666666666, test acc:0.1451 ===\n",
      "train loss:2.2703462892154658\n",
      "train loss:2.270530981924607\n",
      "train loss:2.273708607933521\n",
      "=== epoch:57, train acc:0.17, test acc:0.1459 ===\n",
      "train loss:2.2707305027804434\n",
      "train loss:2.2853420952699945\n",
      "train loss:2.268218676502596\n",
      "=== epoch:58, train acc:0.17, test acc:0.1472 ===\n",
      "train loss:2.2656755593352322\n",
      "train loss:2.2750482575035327\n",
      "train loss:2.2772958579191744\n",
      "=== epoch:59, train acc:0.17, test acc:0.149 ===\n",
      "train loss:2.276089102760004\n",
      "train loss:2.25931601003964\n",
      "train loss:2.2686834943513103\n",
      "=== epoch:60, train acc:0.17333333333333334, test acc:0.1498 ===\n",
      "train loss:2.268224553615809\n",
      "train loss:2.2735899546752365\n",
      "train loss:2.2691635004100688\n",
      "=== epoch:61, train acc:0.16666666666666666, test acc:0.15 ===\n",
      "train loss:2.2719028001216794\n",
      "train loss:2.2719889231881636\n",
      "train loss:2.271849806274275\n",
      "=== epoch:62, train acc:0.16666666666666666, test acc:0.1542 ===\n",
      "train loss:2.2591568470639776\n",
      "train loss:2.2586505129786127\n",
      "train loss:2.26188241621378\n",
      "=== epoch:63, train acc:0.17, test acc:0.1554 ===\n",
      "train loss:2.26333141563244\n",
      "train loss:2.27645449623734\n",
      "train loss:2.2712832191836934\n",
      "=== epoch:64, train acc:0.18, test acc:0.1565 ===\n",
      "train loss:2.26789252333886\n",
      "train loss:2.2740967907791556\n",
      "train loss:2.279004072863686\n",
      "=== epoch:65, train acc:0.18333333333333332, test acc:0.1582 ===\n",
      "train loss:2.2711663106536744\n",
      "train loss:2.258043216966252\n",
      "train loss:2.26105381516995\n",
      "=== epoch:66, train acc:0.18333333333333332, test acc:0.1575 ===\n",
      "train loss:2.2719128832213347\n",
      "train loss:2.2514528346620675\n",
      "train loss:2.2554575070883858\n",
      "=== epoch:67, train acc:0.18333333333333332, test acc:0.1545 ===\n",
      "train loss:2.26105439220773\n",
      "train loss:2.2626625076204614\n",
      "train loss:2.2687671966133336\n",
      "=== epoch:68, train acc:0.18666666666666668, test acc:0.1535 ===\n",
      "train loss:2.267035175231622\n",
      "train loss:2.2650932148699594\n",
      "train loss:2.275434299542631\n",
      "=== epoch:69, train acc:0.18333333333333332, test acc:0.1543 ===\n",
      "train loss:2.2580028599027697\n",
      "train loss:2.2564244643430023\n",
      "train loss:2.2673007790282087\n",
      "=== epoch:70, train acc:0.17333333333333334, test acc:0.1548 ===\n",
      "train loss:2.2626102661609293\n",
      "train loss:2.259208164976448\n",
      "train loss:2.2515319980338457\n",
      "=== epoch:71, train acc:0.18, test acc:0.1587 ===\n",
      "train loss:2.251590298857669\n",
      "train loss:2.2582090549751084\n",
      "train loss:2.25032891212279\n",
      "=== epoch:72, train acc:0.17666666666666667, test acc:0.1583 ===\n",
      "train loss:2.285481408762513\n",
      "train loss:2.271499053094372\n",
      "train loss:2.271502317156182\n",
      "=== epoch:73, train acc:0.19333333333333333, test acc:0.1615 ===\n",
      "train loss:2.254752774190396\n",
      "train loss:2.262667917540381\n",
      "train loss:2.2508911835527714\n",
      "=== epoch:74, train acc:0.19333333333333333, test acc:0.1601 ===\n",
      "train loss:2.2676448390625845\n",
      "train loss:2.2499082522588423\n",
      "train loss:2.2639770784167252\n",
      "=== epoch:75, train acc:0.19333333333333333, test acc:0.1619 ===\n",
      "train loss:2.2543155088713447\n",
      "train loss:2.258536783530905\n",
      "train loss:2.253841884903579\n",
      "=== epoch:76, train acc:0.19666666666666666, test acc:0.1627 ===\n",
      "train loss:2.256771868564096\n",
      "train loss:2.2570783549541726\n",
      "train loss:2.273292320069698\n",
      "=== epoch:77, train acc:0.19333333333333333, test acc:0.1621 ===\n",
      "train loss:2.2694478132608267\n",
      "train loss:2.2576571909882155\n",
      "train loss:2.2568011688845364\n",
      "=== epoch:78, train acc:0.19333333333333333, test acc:0.1631 ===\n",
      "train loss:2.247998167689544\n",
      "train loss:2.258429279007929\n",
      "train loss:2.2647808271014926\n",
      "=== epoch:79, train acc:0.19666666666666666, test acc:0.1621 ===\n",
      "train loss:2.2429123698154827\n",
      "train loss:2.2632760492535953\n",
      "train loss:2.2461413435765154\n",
      "=== epoch:80, train acc:0.19333333333333333, test acc:0.1618 ===\n",
      "train loss:2.25134166881407\n",
      "train loss:2.257514420291065\n",
      "train loss:2.259217920298947\n",
      "=== epoch:81, train acc:0.18666666666666668, test acc:0.1616 ===\n",
      "train loss:2.236178515362695\n",
      "train loss:2.2353153585679117\n",
      "train loss:2.2515098710320105\n",
      "=== epoch:82, train acc:0.18666666666666668, test acc:0.1593 ===\n",
      "train loss:2.243683798065725\n",
      "train loss:2.2561807582316558\n",
      "train loss:2.257574518327875\n",
      "=== epoch:83, train acc:0.19, test acc:0.1586 ===\n",
      "train loss:2.256301578935381\n",
      "train loss:2.259986268473519\n",
      "train loss:2.242355355432107\n",
      "=== epoch:84, train acc:0.19, test acc:0.1577 ===\n",
      "train loss:2.23980557034399\n",
      "train loss:2.2531208503795854\n",
      "train loss:2.2480991204160623\n",
      "=== epoch:85, train acc:0.19, test acc:0.1589 ===\n",
      "train loss:2.237963912380085\n",
      "train loss:2.245934776072092\n",
      "train loss:2.2494009706185083\n",
      "=== epoch:86, train acc:0.19, test acc:0.162 ===\n",
      "train loss:2.2503804719705225\n",
      "train loss:2.2302883377295704\n",
      "train loss:2.24295352097339\n",
      "=== epoch:87, train acc:0.2, test acc:0.167 ===\n",
      "train loss:2.239708343292747\n",
      "train loss:2.241107105172186\n",
      "train loss:2.2382675996108428\n",
      "=== epoch:88, train acc:0.2, test acc:0.1642 ===\n",
      "train loss:2.2319655633607773\n",
      "train loss:2.238266415699404\n",
      "train loss:2.233364003397614\n",
      "=== epoch:89, train acc:0.19666666666666666, test acc:0.1632 ===\n",
      "train loss:2.2576527034537617\n",
      "train loss:2.2443994137309153\n",
      "train loss:2.2343903854808476\n",
      "=== epoch:90, train acc:0.20666666666666667, test acc:0.1652 ===\n",
      "train loss:2.237676559781208\n",
      "train loss:2.2483431886451704\n",
      "train loss:2.228026737214445\n",
      "=== epoch:91, train acc:0.2, test acc:0.1649 ===\n",
      "train loss:2.22513619568857\n",
      "train loss:2.2577809052127376\n",
      "train loss:2.255481588359885\n",
      "=== epoch:92, train acc:0.21, test acc:0.1703 ===\n",
      "train loss:2.250256094513087\n",
      "train loss:2.2479823764623346\n",
      "train loss:2.2360891118727895\n",
      "=== epoch:93, train acc:0.22666666666666666, test acc:0.1765 ===\n",
      "train loss:2.2366939885070924\n",
      "train loss:2.2327871978692584\n",
      "train loss:2.235231077456014\n",
      "=== epoch:94, train acc:0.22333333333333333, test acc:0.1753 ===\n",
      "train loss:2.2351786854273357\n",
      "train loss:2.2438596552095\n",
      "train loss:2.2479612531272335\n",
      "=== epoch:95, train acc:0.21666666666666667, test acc:0.1767 ===\n",
      "train loss:2.221119279531311\n",
      "train loss:2.230272016092982\n",
      "train loss:2.2466504120599384\n",
      "=== epoch:96, train acc:0.23, test acc:0.1783 ===\n",
      "train loss:2.249161921791042\n",
      "train loss:2.238654650601319\n",
      "train loss:2.2223787641638215\n",
      "=== epoch:97, train acc:0.22666666666666666, test acc:0.1814 ===\n",
      "train loss:2.237381571176476\n",
      "train loss:2.233091952189354\n",
      "train loss:2.2351636679032434\n",
      "=== epoch:98, train acc:0.23, test acc:0.1824 ===\n",
      "train loss:2.247837507599868\n",
      "train loss:2.241281370684351\n",
      "train loss:2.2205544993743094\n",
      "=== epoch:99, train acc:0.24, test acc:0.1845 ===\n",
      "train loss:2.2462092913955773\n",
      "train loss:2.233878048908584\n",
      "train loss:2.233416421837831\n",
      "=== epoch:100, train acc:0.24666666666666667, test acc:0.185 ===\n",
      "train loss:2.2282315540665554\n",
      "train loss:2.2326542480321994\n",
      "train loss:2.212257841195318\n",
      "=== epoch:101, train acc:0.24666666666666667, test acc:0.1865 ===\n",
      "train loss:2.2320861450910527\n",
      "train loss:2.2444730865257077\n",
      "train loss:2.2335726142387675\n",
      "=== epoch:102, train acc:0.24666666666666667, test acc:0.1876 ===\n",
      "train loss:2.2345399674939905\n",
      "train loss:2.2275303459172546\n",
      "train loss:2.2399697585925953\n",
      "=== epoch:103, train acc:0.24666666666666667, test acc:0.1875 ===\n",
      "train loss:2.2239051647285364\n",
      "train loss:2.23651372504217\n",
      "train loss:2.2238231032570117\n",
      "=== epoch:104, train acc:0.24333333333333335, test acc:0.188 ===\n",
      "train loss:2.236506433891118\n",
      "train loss:2.2079085724845853\n",
      "train loss:2.2171608586326887\n",
      "=== epoch:105, train acc:0.24333333333333335, test acc:0.1918 ===\n",
      "train loss:2.2366762873507726\n",
      "train loss:2.22877220032415\n",
      "train loss:2.2260672167718427\n",
      "=== epoch:106, train acc:0.24333333333333335, test acc:0.1923 ===\n",
      "train loss:2.2321370445415245\n",
      "train loss:2.2025149823619277\n",
      "train loss:2.2179536452270767\n",
      "=== epoch:107, train acc:0.24333333333333335, test acc:0.1956 ===\n",
      "train loss:2.215476385809561\n",
      "train loss:2.2322241670875456\n",
      "train loss:2.2276243438492553\n",
      "=== epoch:108, train acc:0.25333333333333335, test acc:0.1969 ===\n",
      "train loss:2.2286201590207453\n",
      "train loss:2.2024762224098438\n",
      "train loss:2.1929627601034345\n",
      "=== epoch:109, train acc:0.2633333333333333, test acc:0.1988 ===\n",
      "train loss:2.2177853087374357\n",
      "train loss:2.2070598295342014\n",
      "train loss:2.2399349144616734\n",
      "=== epoch:110, train acc:0.2633333333333333, test acc:0.1978 ===\n",
      "train loss:2.217127208938048\n",
      "train loss:2.221017166681146\n",
      "train loss:2.2020172877608517\n",
      "=== epoch:111, train acc:0.25, test acc:0.1945 ===\n",
      "train loss:2.2208375049096416\n",
      "train loss:2.23080631448639\n",
      "train loss:2.241568097358106\n",
      "=== epoch:112, train acc:0.26, test acc:0.1978 ===\n",
      "train loss:2.23628421798821\n",
      "train loss:2.2201927615225845\n",
      "train loss:2.229398790330965\n",
      "=== epoch:113, train acc:0.2633333333333333, test acc:0.1982 ===\n",
      "train loss:2.22030405759445\n",
      "train loss:2.216257869769658\n",
      "train loss:2.2291467450774145\n",
      "=== epoch:114, train acc:0.2866666666666667, test acc:0.2051 ===\n",
      "train loss:2.231089978030425\n",
      "train loss:2.2115297910923704\n",
      "train loss:2.216384908346416\n",
      "=== epoch:115, train acc:0.28, test acc:0.2024 ===\n",
      "train loss:2.1979848543321694\n",
      "train loss:2.2284185907958123\n",
      "train loss:2.1865657816516078\n",
      "=== epoch:116, train acc:0.2833333333333333, test acc:0.2044 ===\n",
      "train loss:2.207029478974833\n",
      "train loss:2.2125787191289437\n",
      "train loss:2.218563218767369\n",
      "=== epoch:117, train acc:0.2966666666666667, test acc:0.2092 ===\n",
      "train loss:2.208082179372361\n",
      "train loss:2.2114050954699156\n",
      "train loss:2.2072239371809887\n",
      "=== epoch:118, train acc:0.31333333333333335, test acc:0.221 ===\n",
      "train loss:2.1738547207490573\n",
      "train loss:2.2303642901564578\n",
      "train loss:2.2207782076658655\n",
      "=== epoch:119, train acc:0.3, test acc:0.2153 ===\n",
      "train loss:2.2131459187730105\n",
      "train loss:2.197447216077299\n",
      "train loss:2.215543197203586\n",
      "=== epoch:120, train acc:0.30333333333333334, test acc:0.2191 ===\n",
      "train loss:2.206916240442769\n",
      "train loss:2.2184462570852417\n",
      "train loss:2.1911342585149884\n",
      "=== epoch:121, train acc:0.3, test acc:0.2133 ===\n",
      "train loss:2.19154717926522\n",
      "train loss:2.2097506138079996\n",
      "train loss:2.2058153942424115\n",
      "=== epoch:122, train acc:0.29333333333333333, test acc:0.2124 ===\n",
      "train loss:2.200119161626803\n",
      "train loss:2.2189679608668476\n",
      "train loss:2.2054993153333253\n",
      "=== epoch:123, train acc:0.29333333333333333, test acc:0.2137 ===\n",
      "train loss:2.21292045161137\n",
      "train loss:2.178558786409338\n",
      "train loss:2.212668220758937\n",
      "=== epoch:124, train acc:0.3, test acc:0.2168 ===\n",
      "train loss:2.1956171634439428\n",
      "train loss:2.225847579808911\n",
      "train loss:2.2518559893280052\n",
      "=== epoch:125, train acc:0.30666666666666664, test acc:0.2208 ===\n",
      "train loss:2.2211329146033187\n",
      "train loss:2.1950095688528406\n",
      "train loss:2.2015753395901756\n",
      "=== epoch:126, train acc:0.3233333333333333, test acc:0.2317 ===\n",
      "train loss:2.21443265668968\n",
      "train loss:2.175688444428142\n",
      "train loss:2.1800949296569114\n",
      "=== epoch:127, train acc:0.32, test acc:0.2387 ===\n",
      "train loss:2.2143955804013786\n",
      "train loss:2.1859567790472063\n",
      "train loss:2.165731775182492\n",
      "=== epoch:128, train acc:0.32666666666666666, test acc:0.2401 ===\n",
      "train loss:2.1949998600069645\n",
      "train loss:2.193484239375022\n",
      "train loss:2.2044799166193374\n",
      "=== epoch:129, train acc:0.33666666666666667, test acc:0.2447 ===\n",
      "train loss:2.2155096974814086\n",
      "train loss:2.1793769298063483\n",
      "train loss:2.2072264605421164\n",
      "=== epoch:130, train acc:0.34, test acc:0.2504 ===\n",
      "train loss:2.2103482957681453\n",
      "train loss:2.177450700352379\n",
      "train loss:2.2093688784497587\n",
      "=== epoch:131, train acc:0.36, test acc:0.2558 ===\n",
      "train loss:2.202718482670241\n",
      "train loss:2.187687908628721\n",
      "train loss:2.1977119954415056\n",
      "=== epoch:132, train acc:0.36333333333333334, test acc:0.2599 ===\n",
      "train loss:2.1408645329627216\n",
      "train loss:2.192004384304237\n",
      "train loss:2.1714666271896608\n",
      "=== epoch:133, train acc:0.35, test acc:0.2498 ===\n",
      "train loss:2.225602113887298\n",
      "train loss:2.2071339318630057\n",
      "train loss:2.1887860051027515\n",
      "=== epoch:134, train acc:0.36, test acc:0.2576 ===\n",
      "train loss:2.185950793578248\n",
      "train loss:2.1799681350838704\n",
      "train loss:2.209531078924933\n",
      "=== epoch:135, train acc:0.36, test acc:0.2568 ===\n",
      "train loss:2.1884320753896156\n",
      "train loss:2.193182126033713\n",
      "train loss:2.1839139963428886\n",
      "=== epoch:136, train acc:0.36, test acc:0.2577 ===\n",
      "train loss:2.160719425030259\n",
      "train loss:2.199109143687668\n",
      "train loss:2.1608971308662794\n",
      "=== epoch:137, train acc:0.36333333333333334, test acc:0.2644 ===\n",
      "train loss:2.196547478033904\n",
      "train loss:2.185177429427385\n",
      "train loss:2.1836669073251653\n",
      "=== epoch:138, train acc:0.37, test acc:0.2689 ===\n",
      "train loss:2.1772170709413197\n",
      "train loss:2.2039182370448143\n",
      "train loss:2.16997555313614\n",
      "=== epoch:139, train acc:0.38, test acc:0.27 ===\n",
      "train loss:2.179558174933511\n",
      "train loss:2.181760312266399\n",
      "train loss:2.1859810109999755\n",
      "=== epoch:140, train acc:0.39, test acc:0.2775 ===\n",
      "train loss:2.166105572001227\n",
      "train loss:2.187220786063407\n",
      "train loss:2.1695551334317287\n",
      "=== epoch:141, train acc:0.37333333333333335, test acc:0.2761 ===\n",
      "train loss:2.169411635892348\n",
      "train loss:2.1672478357106884\n",
      "train loss:2.150623827079436\n",
      "=== epoch:142, train acc:0.3933333333333333, test acc:0.2781 ===\n",
      "train loss:2.175589861595546\n",
      "train loss:2.171679868094972\n",
      "train loss:2.1763698806102365\n",
      "=== epoch:143, train acc:0.38666666666666666, test acc:0.2745 ===\n",
      "train loss:2.158861606525947\n",
      "train loss:2.187468471549886\n",
      "train loss:2.1750931395252637\n",
      "=== epoch:144, train acc:0.38, test acc:0.2743 ===\n",
      "train loss:2.174349728197423\n",
      "train loss:2.174091157638613\n",
      "train loss:2.1612784225981985\n",
      "=== epoch:145, train acc:0.38, test acc:0.2756 ===\n",
      "train loss:2.1812095128705735\n",
      "train loss:2.1463042927823874\n",
      "train loss:2.1733384477381357\n",
      "=== epoch:146, train acc:0.38666666666666666, test acc:0.2805 ===\n",
      "train loss:2.1950080721868592\n",
      "train loss:2.1604657695386025\n",
      "train loss:2.151436547714053\n",
      "=== epoch:147, train acc:0.39, test acc:0.2813 ===\n",
      "train loss:2.1504170607727353\n",
      "train loss:2.1652216479628215\n",
      "train loss:2.1314357353252387\n",
      "=== epoch:148, train acc:0.38666666666666666, test acc:0.2822 ===\n",
      "train loss:2.1807289822240334\n",
      "train loss:2.1643859338860723\n",
      "train loss:2.1418821999564983\n",
      "=== epoch:149, train acc:0.38666666666666666, test acc:0.2813 ===\n",
      "train loss:2.157148881063219\n",
      "train loss:2.1566957417123995\n",
      "train loss:2.155457452005085\n",
      "=== epoch:150, train acc:0.39, test acc:0.2835 ===\n",
      "train loss:2.1538455951331867\n",
      "train loss:2.1728095178647835\n",
      "train loss:2.1262878161147576\n",
      "=== epoch:151, train acc:0.37666666666666665, test acc:0.2809 ===\n",
      "train loss:2.1899495152861466\n",
      "train loss:2.1302195516196587\n",
      "train loss:2.137773455208945\n",
      "=== epoch:152, train acc:0.3933333333333333, test acc:0.2852 ===\n",
      "train loss:2.1395300143096296\n",
      "train loss:2.157262062664668\n",
      "train loss:2.086782405520503\n",
      "=== epoch:153, train acc:0.3933333333333333, test acc:0.2834 ===\n",
      "train loss:2.153333196596141\n",
      "train loss:2.1734416789559994\n",
      "train loss:2.152333159074958\n",
      "=== epoch:154, train acc:0.39, test acc:0.2862 ===\n",
      "train loss:2.154598461579432\n",
      "train loss:2.1420952106112736\n",
      "train loss:2.142369241336724\n",
      "=== epoch:155, train acc:0.41, test acc:0.2931 ===\n",
      "train loss:2.1688550024243582\n",
      "train loss:2.140208722622651\n",
      "train loss:2.1727819968315436\n",
      "=== epoch:156, train acc:0.4266666666666667, test acc:0.3053 ===\n",
      "train loss:2.126755561067225\n",
      "train loss:2.1437632718859145\n",
      "train loss:2.1364311910318325\n",
      "=== epoch:157, train acc:0.42333333333333334, test acc:0.3033 ===\n",
      "train loss:2.162932578908619\n",
      "train loss:2.125717086305978\n",
      "train loss:2.1334012297649343\n",
      "=== epoch:158, train acc:0.42333333333333334, test acc:0.3046 ===\n",
      "train loss:2.1208168910009615\n",
      "train loss:2.1227684211233266\n",
      "train loss:2.1382536718375174\n",
      "=== epoch:159, train acc:0.42, test acc:0.3023 ===\n",
      "train loss:2.1147528841528906\n",
      "train loss:2.1362840974037987\n",
      "train loss:2.136348847962741\n",
      "=== epoch:160, train acc:0.4033333333333333, test acc:0.2994 ===\n",
      "train loss:2.1355633302439854\n",
      "train loss:2.1396460221828413\n",
      "train loss:2.147142482088362\n",
      "=== epoch:161, train acc:0.41333333333333333, test acc:0.301 ===\n",
      "train loss:2.137302298347844\n",
      "train loss:2.101846973928104\n",
      "train loss:2.109560548501862\n",
      "=== epoch:162, train acc:0.42, test acc:0.3033 ===\n",
      "train loss:2.13036109169971\n",
      "train loss:2.1272179571728898\n",
      "train loss:2.0982767313525152\n",
      "=== epoch:163, train acc:0.42333333333333334, test acc:0.3042 ===\n",
      "train loss:2.1412837537915164\n",
      "train loss:2.1245095080416876\n",
      "train loss:2.1249468386850516\n",
      "=== epoch:164, train acc:0.43333333333333335, test acc:0.3077 ===\n",
      "train loss:2.1062788185612917\n",
      "train loss:2.084066819817989\n",
      "train loss:2.0672365975597073\n",
      "=== epoch:165, train acc:0.4266666666666667, test acc:0.3062 ===\n",
      "train loss:2.0852562065406435\n",
      "train loss:2.1004385121505122\n",
      "train loss:2.10608534241698\n",
      "=== epoch:166, train acc:0.43, test acc:0.305 ===\n",
      "train loss:2.080727344268981\n",
      "train loss:2.139541319362463\n",
      "train loss:2.143978341980088\n",
      "=== epoch:167, train acc:0.42, test acc:0.3033 ===\n",
      "train loss:2.0939005906904162\n",
      "train loss:2.124365309571004\n",
      "train loss:2.0670606232740023\n",
      "=== epoch:168, train acc:0.42333333333333334, test acc:0.3006 ===\n",
      "train loss:2.0780284296173703\n",
      "train loss:2.121012250004484\n",
      "train loss:2.118648597803591\n",
      "=== epoch:169, train acc:0.42333333333333334, test acc:0.3001 ===\n",
      "train loss:2.076854906796241\n",
      "train loss:2.1143419987104424\n",
      "train loss:2.1147842356805358\n",
      "=== epoch:170, train acc:0.42, test acc:0.3062 ===\n",
      "train loss:2.10574246936135\n",
      "train loss:2.1103584772370225\n",
      "train loss:2.0955295579223727\n",
      "=== epoch:171, train acc:0.43333333333333335, test acc:0.3072 ===\n",
      "train loss:2.070353594838492\n",
      "train loss:2.08042982083385\n",
      "train loss:2.114408739353269\n",
      "=== epoch:172, train acc:0.43666666666666665, test acc:0.3067 ===\n",
      "train loss:2.069326079701312\n",
      "train loss:2.09108224478045\n",
      "train loss:2.073880853059504\n",
      "=== epoch:173, train acc:0.43666666666666665, test acc:0.304 ===\n",
      "train loss:2.0850529944592124\n",
      "train loss:2.1010520953476126\n",
      "train loss:2.120880172324606\n",
      "=== epoch:174, train acc:0.44, test acc:0.3066 ===\n",
      "train loss:2.0720675322257645\n",
      "train loss:2.0677484292675663\n",
      "train loss:2.0533146444621657\n",
      "=== epoch:175, train acc:0.4266666666666667, test acc:0.3024 ===\n",
      "train loss:2.1070748011854765\n",
      "train loss:2.083307792699901\n",
      "train loss:2.0992670659842223\n",
      "=== epoch:176, train acc:0.4533333333333333, test acc:0.3145 ===\n",
      "train loss:2.0734740414217487\n",
      "train loss:2.086197128083794\n",
      "train loss:2.0843415750479877\n",
      "=== epoch:177, train acc:0.4533333333333333, test acc:0.3145 ===\n",
      "train loss:2.0927281816274506\n",
      "train loss:2.1123414197236254\n",
      "train loss:2.022158659565508\n",
      "=== epoch:178, train acc:0.45666666666666667, test acc:0.3158 ===\n",
      "train loss:2.057209031819014\n",
      "train loss:2.012284049842555\n",
      "train loss:2.084760628587197\n",
      "=== epoch:179, train acc:0.44333333333333336, test acc:0.3112 ===\n",
      "train loss:2.0934654517759186\n",
      "train loss:2.029917277536591\n",
      "train loss:2.004772285042482\n",
      "=== epoch:180, train acc:0.45, test acc:0.3034 ===\n",
      "train loss:2.1019863242707366\n",
      "train loss:2.0981180367917767\n",
      "train loss:2.061929071820318\n",
      "=== epoch:181, train acc:0.45666666666666667, test acc:0.3182 ===\n",
      "train loss:2.045160168174167\n",
      "train loss:2.016755527445524\n",
      "train loss:2.019756661958444\n",
      "=== epoch:182, train acc:0.45, test acc:0.3153 ===\n",
      "train loss:2.0953891221841126\n",
      "train loss:2.078661528954374\n",
      "train loss:2.0324904426420543\n",
      "=== epoch:183, train acc:0.46, test acc:0.3165 ===\n",
      "train loss:2.095915511742637\n",
      "train loss:2.010137270715397\n",
      "train loss:2.0760047822226997\n",
      "=== epoch:184, train acc:0.4533333333333333, test acc:0.3196 ===\n",
      "train loss:2.042758350825503\n",
      "train loss:2.0697957403681584\n",
      "train loss:1.9629018049732616\n",
      "=== epoch:185, train acc:0.4633333333333333, test acc:0.3159 ===\n",
      "train loss:2.052045624779717\n",
      "train loss:2.0848346233947286\n",
      "train loss:2.0419061469789144\n",
      "=== epoch:186, train acc:0.4666666666666667, test acc:0.3211 ===\n",
      "train loss:2.100150044075183\n",
      "train loss:2.017548929747795\n",
      "train loss:2.074973956642304\n",
      "=== epoch:187, train acc:0.47333333333333333, test acc:0.3275 ===\n",
      "train loss:2.053058184818164\n",
      "train loss:2.035055845086956\n",
      "train loss:2.069703611900582\n",
      "=== epoch:188, train acc:0.48333333333333334, test acc:0.3338 ===\n",
      "train loss:2.0463619866433236\n",
      "train loss:2.0159097403537167\n",
      "train loss:2.054526134658503\n",
      "=== epoch:189, train acc:0.48333333333333334, test acc:0.3368 ===\n",
      "train loss:2.075694837952569\n",
      "train loss:2.061022975602222\n",
      "train loss:2.025345445904133\n",
      "=== epoch:190, train acc:0.48333333333333334, test acc:0.3368 ===\n",
      "train loss:2.0097676155246385\n",
      "train loss:2.0171997702057687\n",
      "train loss:2.0262668465489977\n",
      "=== epoch:191, train acc:0.48, test acc:0.3352 ===\n",
      "train loss:2.051021432090508\n",
      "train loss:2.055783493504785\n",
      "train loss:2.0355949446078343\n",
      "=== epoch:192, train acc:0.4866666666666667, test acc:0.3454 ===\n",
      "train loss:1.976250160246568\n",
      "train loss:2.0235443195550804\n",
      "train loss:2.0536317776899713\n",
      "=== epoch:193, train acc:0.4866666666666667, test acc:0.3483 ===\n",
      "train loss:2.0103348869360325\n",
      "train loss:1.9782951696062505\n",
      "train loss:2.0711136873452\n",
      "=== epoch:194, train acc:0.49333333333333335, test acc:0.349 ===\n",
      "train loss:1.9442543881766456\n",
      "train loss:2.041232492456219\n",
      "train loss:1.9433527586407273\n",
      "=== epoch:195, train acc:0.4866666666666667, test acc:0.3463 ===\n",
      "train loss:2.054983522268434\n",
      "train loss:2.0602731002653716\n",
      "train loss:2.0010352372944245\n",
      "=== epoch:196, train acc:0.49666666666666665, test acc:0.352 ===\n",
      "train loss:2.0126916355899476\n",
      "train loss:2.009649547871384\n",
      "train loss:2.049557376338779\n",
      "=== epoch:197, train acc:0.49666666666666665, test acc:0.3503 ===\n",
      "train loss:2.0335871739074243\n",
      "train loss:2.0235539782081253\n",
      "train loss:2.003288507813073\n",
      "=== epoch:198, train acc:0.49666666666666665, test acc:0.3545 ===\n",
      "train loss:2.016823580346435\n",
      "train loss:2.0168744772709073\n",
      "train loss:2.0436313727411015\n",
      "=== epoch:199, train acc:0.51, test acc:0.3605 ===\n",
      "train loss:2.0073129338934894\n",
      "train loss:2.0008934789800694\n",
      "train loss:2.039812549289314\n",
      "=== epoch:200, train acc:0.51, test acc:0.3669 ===\n",
      "train loss:2.073650520679589\n",
      "train loss:1.9956783086806404\n",
      "train loss:2.002317963446332\n",
      "=== epoch:201, train acc:0.5166666666666667, test acc:0.3732 ===\n",
      "train loss:1.9827477174359072\n",
      "train loss:2.0421703306668646\n",
      "train loss:1.8980193477151424\n",
      "=== epoch:202, train acc:0.5166666666666667, test acc:0.3746 ===\n",
      "train loss:2.0192029529789455\n",
      "train loss:2.02123374606203\n",
      "train loss:1.9800174540603015\n",
      "=== epoch:203, train acc:0.5166666666666667, test acc:0.3816 ===\n",
      "train loss:1.9918518727246695\n",
      "train loss:2.0360848098006925\n",
      "train loss:1.9297948881681435\n",
      "=== epoch:204, train acc:0.5233333333333333, test acc:0.3772 ===\n",
      "train loss:1.9922909077688131\n",
      "train loss:2.1263340940436475\n",
      "train loss:2.049089154355078\n",
      "=== epoch:205, train acc:0.5266666666666666, test acc:0.3962 ===\n",
      "train loss:1.9933261053162223\n",
      "train loss:1.9649139952549175\n",
      "train loss:1.9504156446868215\n",
      "=== epoch:206, train acc:0.5233333333333333, test acc:0.3891 ===\n",
      "train loss:1.9879201245608136\n",
      "train loss:1.957576322098644\n",
      "train loss:2.0289712127136665\n",
      "=== epoch:207, train acc:0.5333333333333333, test acc:0.3946 ===\n",
      "train loss:1.9205672671295724\n",
      "train loss:1.96573713074391\n",
      "train loss:2.015881877129677\n",
      "=== epoch:208, train acc:0.53, test acc:0.3955 ===\n",
      "train loss:1.9964265043859886\n",
      "train loss:2.0049535656679107\n",
      "train loss:2.016685424126056\n",
      "=== epoch:209, train acc:0.53, test acc:0.3948 ===\n",
      "train loss:1.9448505642767253\n",
      "train loss:1.9849183507623192\n",
      "train loss:1.9173260031592891\n",
      "=== epoch:210, train acc:0.54, test acc:0.3962 ===\n",
      "train loss:1.946798678370425\n",
      "train loss:1.9450613133792287\n",
      "train loss:1.924340342456233\n",
      "=== epoch:211, train acc:0.5333333333333333, test acc:0.399 ===\n",
      "train loss:1.9295834026044474\n",
      "train loss:1.9623723026348587\n",
      "train loss:1.989348429965117\n",
      "=== epoch:212, train acc:0.5433333333333333, test acc:0.4003 ===\n",
      "train loss:1.9327194841063977\n",
      "train loss:1.8779059815527892\n",
      "train loss:1.9711518131702106\n",
      "=== epoch:213, train acc:0.5466666666666666, test acc:0.4034 ===\n",
      "train loss:1.9715223574607523\n",
      "train loss:1.958617369181946\n",
      "train loss:1.9598291939165906\n",
      "=== epoch:214, train acc:0.5466666666666666, test acc:0.4116 ===\n",
      "train loss:1.922362748718561\n",
      "train loss:2.0247252082720126\n",
      "train loss:1.9386932637559442\n",
      "=== epoch:215, train acc:0.55, test acc:0.4126 ===\n",
      "train loss:1.9720887356687633\n",
      "train loss:1.9491575419668823\n",
      "train loss:1.9423281087713986\n",
      "=== epoch:216, train acc:0.5466666666666666, test acc:0.4143 ===\n",
      "train loss:1.934631589935056\n",
      "train loss:1.9540986033696286\n",
      "train loss:1.9852784033720972\n",
      "=== epoch:217, train acc:0.5433333333333333, test acc:0.4141 ===\n",
      "train loss:1.9721416492073283\n",
      "train loss:2.0192970118783915\n",
      "train loss:1.9817893073097053\n",
      "=== epoch:218, train acc:0.54, test acc:0.4237 ===\n",
      "train loss:1.9793132141963516\n",
      "train loss:1.94598018264523\n",
      "train loss:1.914408188201933\n",
      "=== epoch:219, train acc:0.55, test acc:0.4285 ===\n",
      "train loss:1.9166729675604222\n",
      "train loss:1.9648105885348601\n",
      "train loss:1.9281668106399183\n",
      "=== epoch:220, train acc:0.5466666666666666, test acc:0.4273 ===\n",
      "train loss:1.976058248729555\n",
      "train loss:1.8941320140195432\n",
      "train loss:1.9488622416266248\n",
      "=== epoch:221, train acc:0.5466666666666666, test acc:0.4295 ===\n",
      "train loss:1.9498766102503142\n",
      "train loss:1.8594843614285148\n",
      "train loss:1.8816593723264519\n",
      "=== epoch:222, train acc:0.5533333333333333, test acc:0.4295 ===\n",
      "train loss:1.946243352783211\n",
      "train loss:1.8996212182981225\n",
      "train loss:1.8403640137916073\n",
      "=== epoch:223, train acc:0.5666666666666667, test acc:0.4318 ===\n",
      "train loss:1.9333502524920008\n",
      "train loss:1.8891533256727058\n",
      "train loss:1.9621491874352908\n",
      "=== epoch:224, train acc:0.5633333333333334, test acc:0.4321 ===\n",
      "train loss:1.938560535464528\n",
      "train loss:1.9141480319149209\n",
      "train loss:1.846640550667886\n",
      "=== epoch:225, train acc:0.5666666666666667, test acc:0.4344 ===\n",
      "train loss:1.886195796516622\n",
      "train loss:1.9010552592876806\n",
      "train loss:1.8878064165338733\n",
      "=== epoch:226, train acc:0.5566666666666666, test acc:0.4315 ===\n",
      "train loss:1.8860634529615659\n",
      "train loss:1.9121375636534503\n",
      "train loss:1.8351919866563526\n",
      "=== epoch:227, train acc:0.5666666666666667, test acc:0.4353 ===\n",
      "train loss:1.918917330237061\n",
      "train loss:1.7827510873796046\n",
      "train loss:1.9210264360556624\n",
      "=== epoch:228, train acc:0.5633333333333334, test acc:0.4359 ===\n",
      "train loss:1.9280613943529303\n",
      "train loss:1.8118746228378373\n",
      "train loss:1.8845702908622295\n",
      "=== epoch:229, train acc:0.56, test acc:0.4349 ===\n",
      "train loss:1.8739409672778051\n",
      "train loss:1.855639236825976\n",
      "train loss:1.894879246898977\n",
      "=== epoch:230, train acc:0.5633333333333334, test acc:0.4369 ===\n",
      "train loss:1.8633139815017712\n",
      "train loss:1.9339794821087581\n",
      "train loss:1.885703715238855\n",
      "=== epoch:231, train acc:0.5633333333333334, test acc:0.4432 ===\n",
      "train loss:1.7743421714173635\n",
      "train loss:1.7971373987876456\n",
      "train loss:1.8543042233543643\n",
      "=== epoch:232, train acc:0.57, test acc:0.4466 ===\n",
      "train loss:1.8657964786135128\n",
      "train loss:1.886779046655311\n",
      "train loss:1.9004277568137442\n",
      "=== epoch:233, train acc:0.5733333333333334, test acc:0.4525 ===\n",
      "train loss:1.8988131981037513\n",
      "train loss:1.81148613518215\n",
      "train loss:1.9642317351604026\n",
      "=== epoch:234, train acc:0.57, test acc:0.4533 ===\n",
      "train loss:1.8441278010821127\n",
      "train loss:1.864891293287166\n",
      "train loss:1.8592819825480729\n",
      "=== epoch:235, train acc:0.5733333333333334, test acc:0.4521 ===\n",
      "train loss:1.912665893604171\n",
      "train loss:1.8319710187264742\n",
      "train loss:1.8323670510492431\n",
      "=== epoch:236, train acc:0.5733333333333334, test acc:0.4594 ===\n",
      "train loss:1.890961231633531\n",
      "train loss:1.837021565510139\n",
      "train loss:1.8319014263830906\n",
      "=== epoch:237, train acc:0.5766666666666667, test acc:0.4612 ===\n",
      "train loss:1.8115782465524972\n",
      "train loss:1.9079304098929777\n",
      "train loss:1.9116094231686553\n",
      "=== epoch:238, train acc:0.58, test acc:0.465 ===\n",
      "train loss:1.795604177855221\n",
      "train loss:1.8405997988791072\n",
      "train loss:1.7665881320198855\n",
      "=== epoch:239, train acc:0.58, test acc:0.4618 ===\n",
      "train loss:1.9248304347273757\n",
      "train loss:1.7888701529902369\n",
      "train loss:1.8203605736599462\n",
      "=== epoch:240, train acc:0.58, test acc:0.4651 ===\n",
      "train loss:1.8725692605486999\n",
      "train loss:1.870024374645657\n",
      "train loss:1.9363276002077234\n",
      "=== epoch:241, train acc:0.5866666666666667, test acc:0.4731 ===\n",
      "train loss:1.8158255014857019\n",
      "train loss:1.8034602766995727\n",
      "train loss:1.8818489180166922\n",
      "=== epoch:242, train acc:0.5833333333333334, test acc:0.4721 ===\n",
      "train loss:1.771731940039719\n",
      "train loss:1.74223984171861\n",
      "train loss:1.8219528198047201\n",
      "=== epoch:243, train acc:0.59, test acc:0.4717 ===\n",
      "train loss:1.867996178554284\n",
      "train loss:1.7992339777533226\n",
      "train loss:1.7888181554890303\n",
      "=== epoch:244, train acc:0.5933333333333334, test acc:0.4708 ===\n",
      "train loss:1.7891045465680682\n",
      "train loss:1.7453870209137807\n",
      "train loss:1.8710700615277063\n",
      "=== epoch:245, train acc:0.6, test acc:0.4711 ===\n",
      "train loss:1.8156986244670157\n",
      "train loss:1.8003585709957088\n",
      "train loss:1.7106810547861653\n",
      "=== epoch:246, train acc:0.5966666666666667, test acc:0.4697 ===\n",
      "train loss:1.8005704576586146\n",
      "train loss:1.8450969122802294\n",
      "train loss:1.7215885935973818\n",
      "=== epoch:247, train acc:0.59, test acc:0.4636 ===\n",
      "train loss:1.7750190918921973\n",
      "train loss:1.8629498204409105\n",
      "train loss:1.8168601663387016\n",
      "=== epoch:248, train acc:0.5833333333333334, test acc:0.4669 ===\n",
      "train loss:1.8324454901641791\n",
      "train loss:1.6950396373638923\n",
      "train loss:1.7956075127906164\n",
      "=== epoch:249, train acc:0.5966666666666667, test acc:0.4718 ===\n",
      "train loss:1.7782750016905267\n",
      "train loss:1.8016788019285217\n",
      "train loss:1.7979334606866733\n",
      "=== epoch:250, train acc:0.5933333333333334, test acc:0.4761 ===\n",
      "train loss:1.75485798324614\n",
      "train loss:1.772028129057613\n",
      "train loss:1.8453725478550502\n",
      "=== epoch:251, train acc:0.5966666666666667, test acc:0.4828 ===\n",
      "train loss:1.7840990136666792\n",
      "train loss:1.707575430844424\n",
      "train loss:1.8299637461604927\n",
      "=== epoch:252, train acc:0.6033333333333334, test acc:0.4836 ===\n",
      "train loss:1.7924592601234377\n",
      "train loss:1.7336007096212773\n",
      "train loss:1.751021874202863\n",
      "=== epoch:253, train acc:0.61, test acc:0.4876 ===\n",
      "train loss:1.6524966846298617\n",
      "train loss:1.6694888702724362\n",
      "train loss:1.7485255957231467\n",
      "=== epoch:254, train acc:0.6, test acc:0.4868 ===\n",
      "train loss:1.7667549653242363\n",
      "train loss:1.8457894471707732\n",
      "train loss:1.771352312374464\n",
      "=== epoch:255, train acc:0.61, test acc:0.4878 ===\n",
      "train loss:1.840967896986449\n",
      "train loss:1.6904289344366492\n",
      "train loss:1.7555154823752182\n",
      "=== epoch:256, train acc:0.5933333333333334, test acc:0.485 ===\n",
      "train loss:1.711266010180863\n",
      "train loss:1.7252200621708444\n",
      "train loss:1.706422651535381\n",
      "=== epoch:257, train acc:0.5966666666666667, test acc:0.4874 ===\n",
      "train loss:1.732248385822493\n",
      "train loss:1.7372561845844274\n",
      "train loss:1.7969062437187293\n",
      "=== epoch:258, train acc:0.5833333333333334, test acc:0.4896 ===\n",
      "train loss:1.7970410185397603\n",
      "train loss:1.762891510668227\n",
      "train loss:1.7950690929907196\n",
      "=== epoch:259, train acc:0.5866666666666667, test acc:0.4939 ===\n",
      "train loss:1.7114594806660777\n",
      "train loss:1.784527526543565\n",
      "train loss:1.6787191708236364\n",
      "=== epoch:260, train acc:0.59, test acc:0.4964 ===\n",
      "train loss:1.75560777107987\n",
      "train loss:1.8270476752644818\n",
      "train loss:1.6794876374760106\n",
      "=== epoch:261, train acc:0.59, test acc:0.4973 ===\n",
      "train loss:1.66361933687647\n",
      "train loss:1.734062030182305\n",
      "train loss:1.6382545172960845\n",
      "=== epoch:262, train acc:0.5833333333333334, test acc:0.4948 ===\n",
      "train loss:1.6539434205825814\n",
      "train loss:1.7113977722541553\n",
      "train loss:1.730757710779609\n",
      "=== epoch:263, train acc:0.5833333333333334, test acc:0.4946 ===\n",
      "train loss:1.678927896152613\n",
      "train loss:1.7509773191088305\n",
      "train loss:1.6639749331582516\n",
      "=== epoch:264, train acc:0.58, test acc:0.4949 ===\n",
      "train loss:1.6092113255010094\n",
      "train loss:1.739379358357086\n",
      "train loss:1.6186532912847726\n",
      "=== epoch:265, train acc:0.5766666666666667, test acc:0.4954 ===\n",
      "train loss:1.6254559624779206\n",
      "train loss:1.7367662498120198\n",
      "train loss:1.6734732355168296\n",
      "=== epoch:266, train acc:0.5733333333333334, test acc:0.49 ===\n",
      "train loss:1.7776001005272553\n",
      "train loss:1.7354132981570378\n",
      "train loss:1.7326781757522582\n",
      "=== epoch:267, train acc:0.5933333333333334, test acc:0.5004 ===\n",
      "train loss:1.782096882352954\n",
      "train loss:1.613480804006231\n",
      "train loss:1.6998869459066963\n",
      "=== epoch:268, train acc:0.6, test acc:0.5048 ===\n",
      "train loss:1.7963326966074016\n",
      "train loss:1.6912696777106944\n",
      "train loss:1.7066102565647225\n",
      "=== epoch:269, train acc:0.5966666666666667, test acc:0.5038 ===\n",
      "train loss:1.62107000324376\n",
      "train loss:1.6338978731340346\n",
      "train loss:1.6309435070787959\n",
      "=== epoch:270, train acc:0.5933333333333334, test acc:0.5043 ===\n",
      "train loss:1.582206719852218\n",
      "train loss:1.7099036252465816\n",
      "train loss:1.6853796394825105\n",
      "=== epoch:271, train acc:0.6366666666666667, test acc:0.511 ===\n",
      "train loss:1.614546568647041\n",
      "train loss:1.6680260826674074\n",
      "train loss:1.6734767597252607\n",
      "=== epoch:272, train acc:0.6433333333333333, test acc:0.5136 ===\n",
      "train loss:1.576385143801813\n",
      "train loss:1.763992187998536\n",
      "train loss:1.6501584411369838\n",
      "=== epoch:273, train acc:0.64, test acc:0.5141 ===\n",
      "train loss:1.5982520804649514\n",
      "train loss:1.6286729916513412\n",
      "train loss:1.6703292150172908\n",
      "=== epoch:274, train acc:0.63, test acc:0.5169 ===\n",
      "train loss:1.6725090924193224\n",
      "train loss:1.6822138432264233\n",
      "train loss:1.640800146100661\n",
      "=== epoch:275, train acc:0.63, test acc:0.5159 ===\n",
      "train loss:1.7027094553386148\n",
      "train loss:1.6540192760872032\n",
      "train loss:1.5647217396916941\n",
      "=== epoch:276, train acc:0.6333333333333333, test acc:0.5137 ===\n",
      "train loss:1.6698103361997472\n",
      "train loss:1.742681294107523\n",
      "train loss:1.5438221998725579\n",
      "=== epoch:277, train acc:0.6333333333333333, test acc:0.5149 ===\n",
      "train loss:1.5988443182219383\n",
      "train loss:1.6256145588120077\n",
      "train loss:1.6336047125332402\n",
      "=== epoch:278, train acc:0.6266666666666667, test acc:0.5163 ===\n",
      "train loss:1.6878607859461345\n",
      "train loss:1.5538991315349302\n",
      "train loss:1.665350807053909\n",
      "=== epoch:279, train acc:0.6266666666666667, test acc:0.5173 ===\n",
      "train loss:1.548481419872628\n",
      "train loss:1.659616549735211\n",
      "train loss:1.5622614216067903\n",
      "=== epoch:280, train acc:0.62, test acc:0.5143 ===\n",
      "train loss:1.4880895923648836\n",
      "train loss:1.629136222156029\n",
      "train loss:1.5850700896162513\n",
      "=== epoch:281, train acc:0.6133333333333333, test acc:0.5112 ===\n",
      "train loss:1.5894663092366492\n",
      "train loss:1.5746050674693945\n",
      "train loss:1.7139528073311365\n",
      "=== epoch:282, train acc:0.6166666666666667, test acc:0.513 ===\n",
      "train loss:1.557235426012088\n",
      "train loss:1.6330957777245094\n",
      "train loss:1.5261065952378667\n",
      "=== epoch:283, train acc:0.62, test acc:0.5132 ===\n",
      "train loss:1.5486117085834372\n",
      "train loss:1.5357451297587281\n",
      "train loss:1.5999644950647045\n",
      "=== epoch:284, train acc:0.6333333333333333, test acc:0.5184 ===\n",
      "train loss:1.552013723309495\n",
      "train loss:1.5384380898418915\n",
      "train loss:1.5975788564102293\n",
      "=== epoch:285, train acc:0.6366666666666667, test acc:0.5161 ===\n",
      "train loss:1.5828086429663577\n",
      "train loss:1.4912398793336192\n",
      "train loss:1.5680528069510542\n",
      "=== epoch:286, train acc:0.6233333333333333, test acc:0.5163 ===\n",
      "train loss:1.5333527048336206\n",
      "train loss:1.6836796669935288\n",
      "train loss:1.6134820665954812\n",
      "=== epoch:287, train acc:0.6266666666666667, test acc:0.5193 ===\n",
      "train loss:1.5225414515509967\n",
      "train loss:1.5397113468574803\n",
      "train loss:1.6059980358356711\n",
      "=== epoch:288, train acc:0.6266666666666667, test acc:0.5168 ===\n",
      "train loss:1.662829302913369\n",
      "train loss:1.51636106484335\n",
      "train loss:1.5365761784668406\n",
      "=== epoch:289, train acc:0.6266666666666667, test acc:0.5197 ===\n",
      "train loss:1.4201757167975624\n",
      "train loss:1.5627927327003237\n",
      "train loss:1.5453254457652053\n",
      "=== epoch:290, train acc:0.61, test acc:0.5138 ===\n",
      "train loss:1.584296954088294\n",
      "train loss:1.4605039896263667\n",
      "train loss:1.635437097566506\n",
      "=== epoch:291, train acc:0.62, test acc:0.5167 ===\n",
      "train loss:1.496222861635182\n",
      "train loss:1.4877667576125129\n",
      "train loss:1.535586393180041\n",
      "=== epoch:292, train acc:0.6133333333333333, test acc:0.5182 ===\n",
      "train loss:1.4070805064433645\n",
      "train loss:1.44347729013356\n",
      "train loss:1.546406461349003\n",
      "=== epoch:293, train acc:0.6333333333333333, test acc:0.5231 ===\n",
      "train loss:1.5286526875935689\n",
      "train loss:1.5103518782787384\n",
      "train loss:1.5868757002356912\n",
      "=== epoch:294, train acc:0.65, test acc:0.523 ===\n",
      "train loss:1.530044402972779\n",
      "train loss:1.6759843840881126\n",
      "train loss:1.473743145661197\n",
      "=== epoch:295, train acc:0.66, test acc:0.5256 ===\n",
      "train loss:1.6206956822950034\n",
      "train loss:1.517544301210299\n",
      "train loss:1.6163363345725927\n",
      "=== epoch:296, train acc:0.6633333333333333, test acc:0.5289 ===\n",
      "train loss:1.4809449092687776\n",
      "train loss:1.4733616479527274\n",
      "train loss:1.524898619538634\n",
      "=== epoch:297, train acc:0.6533333333333333, test acc:0.5239 ===\n",
      "train loss:1.486311224990287\n",
      "train loss:1.447312720318004\n",
      "train loss:1.4360156035757954\n",
      "=== epoch:298, train acc:0.6566666666666666, test acc:0.523 ===\n",
      "train loss:1.4818941549169609\n",
      "train loss:1.5710479552726144\n",
      "train loss:1.3836834052959457\n",
      "=== epoch:299, train acc:0.6566666666666666, test acc:0.5218 ===\n",
      "train loss:1.5367192676577486\n",
      "train loss:1.5546327087408116\n",
      "train loss:1.4540324666291717\n",
      "=== epoch:300, train acc:0.6666666666666666, test acc:0.5304 ===\n",
      "train loss:1.4526985365788518\n",
      "train loss:1.427159691112037\n",
      "train loss:1.5799076601847475\n",
      "=== epoch:301, train acc:0.66, test acc:0.5345 ===\n",
      "train loss:1.4780909312243917\n",
      "train loss:1.4205918787364036\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5313\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 過学習を再現するために、学習データを削減\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# Dropuoutの有無、割り合いの設定 ========================\n",
    "use_dropout = True  # Dropoutなしのときの場合はFalseに\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
    "\n",
    "# グラフの描画==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データとテストデータの隔たりが少なくなった。Dropoutを用いれば表現力の高いネットワークでも過学習を抑制できる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
